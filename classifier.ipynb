{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anupkashyap/malicious-app-classification/blob/main/classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KK3E_iHsKnHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "120a53ae-1045-4703-85bf-55852b14c40b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lazypredict\n",
            "  Downloading lazypredict-0.2.12-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from lazypredict) (1.2.0)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (from lazypredict) (2.2.3)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (from lazypredict) (0.90)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from lazypredict) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lazypredict) (4.64.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lazypredict) (1.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from lazypredict) (1.3.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm->lazypredict) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm->lazypredict) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->lazypredict) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->lazypredict) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->lazypredict) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lazypredict) (3.1.0)\n",
            "Installing collected packages: lazypredict\n",
            "Successfully installed lazypredict-0.2.12\n"
          ]
        }
      ],
      "source": [
        "%pip install lazypredict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "rQefHluAUHDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65766369-35c6-49da-d4fd-d8c8f86b827d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yLKsdY8hK0LZ"
      },
      "outputs": [],
      "source": [
        "#Import libraries\n",
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn import tree\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "import sys\n",
        "sys.stdout=open(\"output.txt\",\"w\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Config\n",
        "PERMISSION_COUNT=75\n",
        "TEST_SIZE=.2\n",
        "DANGEROUS_PERMISSIONS = ['READ_CALENDAR','WRITE_CALENDAR','CAMERA','READ_CONTACTS','WRITE_CONTACTS','GET_ACCOUNTS','ACCESS_FINE_LOCATION','ACCESS_COARSE_LOCATION','RECORD_AUDIO','READ_PHONE_STATE','READ_PHONE_NUMBERS ','CALL_PHONE','ANSWER_PHONE_CALLS ','READ_CALL_LOG','WRITE_CALL_LOG','ADD_VOICEMAIL','USE_SIP','PROCESS_OUTGOING_CALLS','BODY_SENSORS','SEND_SMS','RECEIVE_SMS','READ_SMS','RECEIVE_WAP_PUSH','RECEIVE_MMS','READ_EXTERNAL_STORAGE','WRITE_EXTERNAL_STORAGE','ACCESS_MEDIA_LOCATION','ACCEPT_HANDOVER','ACCESS_BACKGROUND_LOCATION','ACTIVITY_RECOGNITION']\n",
        "FEATURE_LIST=[\"permissions\", \"libraries\",\"activities\", \"files\", \"features\", \"providers\"]"
      ],
      "metadata": {
        "id": "wRLCSrZH9Vl4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KyEj3KmsLdVr"
      },
      "outputs": [],
      "source": [
        "#Load features\n",
        "featuresben = json.load(open('gdrive/MyDrive/featuresBenign.json'))\n",
        "featuresmal = json.load(open('gdrive/MyDrive/featuresMalware.json'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get list of all permissions\n",
        "permissions={}\n",
        "for app in featuresben:\n",
        "\n",
        "  for p in app['permissions']:\n",
        "    permissions[p.split('.')[-1]]=permissions[p.split('.')[-1]]+1 if p in permissions.keys() else 1\n",
        "\n",
        "for app in featuresmal:\n",
        "\n",
        "  for p in app['permissions']:\n",
        "    permissions[p.split('.')[-1]]=permissions[p.split('.')[-1]]+1 if p in permissions.keys() else 1\n",
        "len(permissions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyiXf_OAhsCk",
        "outputId": "ef97d515-b4e3-4924-b6db-8c22c8276e65"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "188"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the top 'PERMISSION_COUNT' permissions\n",
        "dict(sorted(permissions.items(), key=lambda item: item[1],reverse=True))\n",
        "\n",
        "top_permissions=list(permissions.keys())[0:PERMISSION_COUNT-1]\n",
        "\n",
        "print(top_permissions)\n"
      ],
      "metadata": {
        "id": "wwGh_02X9Pj-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create one hot encoding for the frequently used permissions \n",
        "dataframes=[]\n",
        "encoding=[]\n",
        "for app in featuresben:\n",
        "  row=[]\n",
        "  for p in top_permissions:\n",
        "    if(p in [t.split('.')[-1] for t in app['permissions']]):\n",
        "      row.append(1)\n",
        "    else:\n",
        "      row.append(0)\n",
        "  row.append(1 if app['isMalicious'] else 0)\n",
        "  encoding.append(row)\n",
        "benign_df_freq= pd.DataFrame(encoding,columns=[p for p in top_permissions]+['Class'])\n",
        "# benign_df_freq.head()\n",
        "\n",
        "encoding=[]\n",
        "for app in featuresmal:\n",
        "  row=[]\n",
        "  for p in top_permissions:\n",
        "    if(p in [t.split('.')[-1] for t in app['permissions']]):\n",
        "      row.append(1)\n",
        "    else:\n",
        "      row.append(0)\n",
        "  row.append(1 if app['isMalicious'] else 0)\n",
        "  encoding.append(row)\n",
        "malicous_df_freq= pd.DataFrame(encoding,columns=[p for p in top_permissions]+['Class'])\n",
        "# malicous_df_freq.head()\n",
        "\n",
        "dataframes.append((benign_df_freq,malicous_df_freq,\"FREQUENTLY USED PERMISSIONS\"))"
      ],
      "metadata": {
        "id": "Y2hVjTW_WbYT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create one hot encoding for the dangerous permissions \n",
        "encoding=[]\n",
        "for app in featuresben:\n",
        "  row=[]\n",
        "  for p in DANGEROUS_PERMISSIONS:\n",
        "    if(p in [t.split('.')[-1] for t in app['permissions']]):\n",
        "      row.append(1)\n",
        "    else:\n",
        "      row.append(0)\n",
        "  row.append(1 if app['isMalicious'] else 0)\n",
        "  encoding.append(row)\n",
        "benign_df_dangerous= pd.DataFrame(encoding,columns=[p for p in DANGEROUS_PERMISSIONS]+['Class'])\n",
        "#benign_df_dangerous.head()\n",
        "encoding=[]\n",
        "for app in featuresmal:\n",
        "  row=[]\n",
        "  for p in DANGEROUS_PERMISSIONS:\n",
        "    if(p in [t.split('.')[-1] for t in app['permissions']]):\n",
        "      row.append(1)\n",
        "    else:\n",
        "      row.append(0)\n",
        "  row.append(1 if app['isMalicious'] else 0)\n",
        "  encoding.append(row)\n",
        "malicous_df_dangerous= pd.DataFrame(encoding,columns=[p for p in DANGEROUS_PERMISSIONS]+['Class'])\n",
        "#malicous_df_dangerous.head()\n",
        "\n",
        "dataframes.append((benign_df_dangerous,malicous_df_dangerous,\"Dangerous Permissions\"))"
      ],
      "metadata": {
        "id": "DbgM5SHPHARF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Set 2\n",
        "#Extract feature counts from the apps\n",
        "\n",
        "feature_count_benign = []\n",
        "for app in featuresben:\n",
        "  inner_list_ben = []\n",
        "  for key,value in app.items():\n",
        "    if key in FEATURE_LIST:\n",
        "      inner_list_ben.append(len(value))\n",
        "  inner_list_ben.append(1 if key== 'isMalicious' and value == 1 else 0)\n",
        "  feature_count_benign.append(inner_list_ben)\n",
        "\n",
        "#print(feature_count_benign)\n",
        "benign_df_feature_count= pd.DataFrame(feature_count_benign,columns=[f for f in FEATURE_LIST] +[\"Class\"])\n",
        "#malicous_df_feature_count.head()\n",
        "\n",
        "feature_count_malicious = []\n",
        "for app in featuresmal:\n",
        "  inner_list_mal = []\n",
        "  for key,value in app.items():\n",
        "    if key in FEATURE_LIST:\n",
        "      inner_list_mal.append(len(value))\n",
        "  inner_list_mal.append(1 if key== 'isMalicious' and value == 1 else 0)\n",
        "  feature_count_malicious.append(inner_list_mal)\n",
        "\n",
        "#print(feature_count_malicious)\n",
        "malicous_df_feature_count= pd.DataFrame(feature_count_malicious,columns=[f for f in FEATURE_LIST] +[\"Class\"])\n",
        "#malicous_df_feature_count.head()\n",
        "\n",
        "dataframes.append((benign_df_dangerous,malicous_df_dangerous,\"FEATURE COUNT\"))"
      ],
      "metadata": {
        "id": "shhUFtBdL7_s"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature set 3\n",
        "#Combination of all previous features\n",
        "\n",
        "malicous_df_combined= pd.concat([malicous_df_dangerous[malicous_df_dangerous.columns.difference(['Class'])],malicous_df_feature_count ],axis=1)\n",
        "benign_df_combined= pd.concat([benign_df_dangerous[benign_df_dangerous.columns.difference(['Class'])],benign_df_feature_count ],axis=1)\n",
        "dataframes.append((benign_df_combined,malicous_df_combined,\"COMBINED FEATURES\"))\n",
        "print(type(benign_df_combined))\n",
        "print(type(dataframes[3][0]))\n"
      ],
      "metadata": {
        "id": "SnAyWaCROc92"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataframes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0H_2QWjVsAG",
        "outputId": "d3f85ac7-4894-4566-b738-4b19346bc8f6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create test and train dataset splits\n",
        "classifier = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
        "for d in dataframes:\n",
        "  Xb_train, Xb_test, yb_train, yb_test = train_test_split(d[0][d[0].columns.difference(['Class'])], d[0]['Class'],test_size=TEST_SIZE,random_state =123)\n",
        "  Xm_train, Xm_test, ym_train, ym_test = train_test_split(d[1][d[1].columns.difference(['Class'])], d[1]['Class'],test_size=TEST_SIZE,random_state =123)\n",
        "\n",
        "  \n",
        "  models,predictions = classifier.fit(pd.concat([Xb_train,Xm_train]), pd.concat([Xb_test,Xm_test]), pd.concat([yb_train,ym_train]), pd.concat([yb_test,ym_test]))\n",
        "  print(\"\\n\\n\"+\"#\"*30)\n",
        "  print(d[2])\n",
        "  print(models)"
      ],
      "metadata": {
        "id": "9FyJMLPYjtCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "158f7c6d-38a4-4dfc-c795-16fe68a82137"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:04<00:00,  6.46it/s]\n",
            "100%|██████████| 29/29 [00:03<00:00,  7.47it/s]\n",
            "100%|██████████| 29/29 [00:03<00:00,  7.80it/s]\n",
            "100%|██████████| 29/29 [00:03<00:00,  8.46it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest Classifier\n",
        "print(\"\\n\\n\"+\"#\"*30)\n",
        "print(\"RANDOM FOREST CLASSIFIER\")\n",
        "print(\"#\"*30)\n",
        "for d in dataframes:\n",
        " \n",
        "\n",
        "  Xb_train, Xb_test, yb_train, yb_test = train_test_split(d[0][d[0].columns.difference(['Class'])], d[0]['Class'],test_size=TEST_SIZE,random_state =123)\n",
        "  Xm_train, Xm_test, ym_train, ym_test = train_test_split(d[1][d[1].columns.difference(['Class'])], d[1]['Class'],test_size=TEST_SIZE,random_state =123)\n",
        "\n",
        "  \n",
        "  X = pd.concat([Xb_train, Xm_train])\n",
        "  y = pd.concat([yb_train, ym_train])              \n",
        "  mod = RandomForestClassifier(max_depth=5, random_state=0)\n",
        "  print(\"\\n\\n\"+\"-\"*30)\n",
        "  print(d[2])\n",
        "  print(\"-\"*30)\n",
        "  mod.fit(X, y)\n",
        "  print(\"Accuracy :\",mod.score(pd.concat([Xb_test,Xm_test]),pd.concat([yb_test,ym_test])))\n",
        "  scores = cross_validate(mod, X, y, cv=5, scoring = ['f1','precision','accuracy'])\n",
        "  for s in scores:\n",
        "    print(s,scores[s])"
      ],
      "metadata": {
        "id": "lU5STLhqm6aY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree Classifier\n",
        "print(\"\\n\\n\"+\"#\"*30)\n",
        "print(\"DECISION TREE CLASSIFIER\")\n",
        "print(\"#\"*30)\n",
        "for d in dataframes:\n",
        "  print(\"\\n\\n\"+\"#\"*30)\n",
        "  print(\"DECISION TREE CLASSIFIER\")\n",
        "  print(\"#\"*30)\n",
        "\n",
        "  Xb_train, Xb_test, yb_train, yb_test = train_test_split(d[0][d[0].columns.difference(['Class'])], d[0]['Class'],test_size=TEST_SIZE,random_state =123)\n",
        "  Xm_train, Xm_test, ym_train, ym_test = train_test_split(d[1][d[1].columns.difference(['Class'])], d[1]['Class'],test_size=TEST_SIZE,random_state =123)\n",
        "\n",
        "  \n",
        "  X = pd.concat([Xb_train, Xm_train])\n",
        "  y = pd.concat([yb_train, ym_train])              \n",
        "  mod = tree.DecisionTreeClassifier()\n",
        "  print(\"\\n\\n\"+\"-\"*30)\n",
        "  print(d[2])\n",
        "  print(\"-\"*30)\n",
        "  mod.fit(X, y)\n",
        "  print(\"Accuracy :\",mod.score(pd.concat([Xb_test,Xm_test]),pd.concat([yb_test,ym_test])))\n",
        "  scores = cross_validate(mod, X, y, cv=5, scoring = ['f1','precision','accuracy'])\n",
        "  for s in scores:\n",
        "    print(s,scores[s])"
      ],
      "metadata": {
        "id": "gwUJn82wZ8g_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SVC Classifier\n",
        "print(\"\\n\\n\"+\"#\"*30)\n",
        "print(\"Support Vector CLASSIFIER\")\n",
        "print(\"#\"*30)\n",
        "\n",
        "for d in dataframes:\n",
        "\n",
        "  Xb_train, Xb_test, yb_train, yb_test = train_test_split(d[0][d[0].columns.difference(['Class'])], d[0]['Class'],test_size=TEST_SIZE,random_state =123)\n",
        "  Xm_train, Xm_test, ym_train, ym_test = train_test_split(d[1][d[1].columns.difference(['Class'])], d[1]['Class'],test_size=TEST_SIZE,random_state =123)\n",
        "\n",
        "  \n",
        "  X = pd.concat([Xb_train, Xm_train])\n",
        "  y = pd.concat([yb_train, ym_train])              \n",
        "  mod = SVC(gamma = 'auto')\n",
        "  print(\"\\n\\n\"+\"-\"*30)\n",
        "  print(d[2])\n",
        "  print(\"-\"*30)\n",
        "  mod.fit(X, y)\n",
        "  print(\"Accuracy :\",mod.score(pd.concat([Xb_test,Xm_test]),pd.concat([yb_test,ym_test])))\n",
        "  scores = cross_validate(mod, X, y, cv=5, scoring = ['f1','precision','accuracy'])\n",
        "  for s in scores:\n",
        "    print(s,scores[s])"
      ],
      "metadata": {
        "id": "O7s5l1kCclDd"
      },
      "execution_count": 16,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}